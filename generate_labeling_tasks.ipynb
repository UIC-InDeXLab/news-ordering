{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6d99c61e-d850-4781-8444-450e719a7067",
   "metadata": {
    "tags": []
   },
   "source": [
    "## read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7ee9564a-82f7-400e-93b9-7ca5ededfbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "77be3d5c-67b6-45d7-a242-724c7fac5a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading at.txt...\n",
      "reading tf.txt...\n"
     ]
    }
   ],
   "source": [
    "sources = []\n",
    "with os.scandir(\"./data/2022-07/headlines\") as directory:\n",
    "    for entry in directory:\n",
    "        if entry.is_file():\n",
    "            print(f\"reading {entry.name}...\")\n",
    "            source_id = entry.name[0]\n",
    "            with open(entry.path) as file:\n",
    "                headlines = []\n",
    "                for i, line in enumerate(file.readlines()):\n",
    "                    headlines.append(f\"({source_id}{str(i)}) {line.strip()}\")\n",
    "                sources.append(headlines)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "16d2db87-166b-4b97-a313-9567a4fc43d1",
   "metadata": {},
   "source": [
    "## generate pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "858ddb05-4e24-4aa8-9788-0dbc9d0a6624",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = []\n",
    "for s in sources:\n",
    "    for i in range(len(s)-1):\n",
    "        for j in range(i+1,len(s)):\n",
    "            pairs.append((s[i],s[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "475d582a-5263-4611-b353-34ab2d07ceb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "48a488bf-7e4d-40de-8b9d-5c1570e0793f",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(pairs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2741d977-a46c-4e6c-8a03-92415f12092f",
   "metadata": {},
   "source": [
    "## assign labelers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6225559f-a7eb-4c50-8e54-8f9db042f207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dd6253c2-7eac-4583-a5c8-3e214b786034",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labelers = 10\n",
    "redundancy = 5\n",
    "assert redundancy <= num_labelers \n",
    "\n",
    "task_size = len(pairs) * redundancy / num_labelers\n",
    "assert task_size == int(task_size)  # if it doesn't divide evenly, need to be more careful with partitioning\n",
    "\n",
    "split_pairs = [ [] for _ in range(num_labelers) ]\n",
    "\n",
    "i = 0\n",
    "count = 0\n",
    "for p in itertools.cycle(pairs):\n",
    "    assert p not in split_pairs[i]  # sanity check\n",
    "    split_pairs[i].append(p)\n",
    "    count += 1\n",
    "    if count % task_size == 0:\n",
    "        i += 1\n",
    "    if count == len(pairs) * redundancy:\n",
    "        break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9bc2f77d-bb28-48e3-b560-494ee8a6ce13",
   "metadata": {},
   "source": [
    "## write data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a0282d5a-e7ee-490c-b0ce-e9b4262bcf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_per_minute = 2.5\n",
    "expected_time = int(task_size / labels_per_minute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f5b05451-1001-4871-8abc-21ec25a320d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_labelers):\n",
    "    with open(f\"./data/to_label/set_{i+1}.txt\", \"w\") as file:\n",
    "        data = f\"\"\"Suppose an average adult residing in the United States is viewing news headlines.\n",
    "If the subject views headline A and headline B together,\n",
    "will their impression of either story likely be different\n",
    "from what it would have been if the subject had viewed them individually?\n",
    "I.e., would viewing the headline of one story influence their\n",
    "opinion on the veracity of the content of the other story or\n",
    "the causes, effects, or benefits of the events discussed within?\n",
    "\n",
    "For each question, you may answer \"yes\", \"no\", or \"maybe\".\n",
    "Please replace \"Y/N/M\" with the corresponding letter.\n",
    "\n",
    "There are a total of {len(split_pairs[i])} questions.\n",
    "The task is estimated to take {expected_time} minutes to complete.\n",
    "\n",
    "{'-'*20}\n",
    "\n",
    "\"\"\"\n",
    "        for j, line in enumerate(split_pairs[i]):\n",
    "            data += f\"#{j+1}\\n{line[0]}\\n{line[1]}\\nY/N/M\\n\\n{'-'*20}\\n\\n\"\n",
    "        \n",
    "        file.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c41e78-202f-4977-ab69-f572a368b5e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:news-ordering]",
   "language": "python",
   "name": "conda-env-news-ordering-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
